@inproceedings{hudgins2020informal,
  title={Informal Learning Communities: The Other Massive Open Online `C'},
  author={Hudgins, Will and Lynch, Matthew and Schmal, Andrew and Sikka, Harsh and Swenson, Arthur and Joyner, David A},
  booktitle={Proceedings of the Seventh ACM Conference on Learning@Scale},
  pages={305--308},
  year={2020},
  publisher={ACM},
  doi={10.1145/3386527.3405926},
  abstract={While the literature on learning at scale has largely focused on MOOCs, online degree programs, and AI techniques for supporting scalable learning experiences, informal learning communities have been relatively underrepresented. None-theless, these massive open online learning communities regularly draw far more engaged users than the typical MOOC. Their informal structure, however, makes them significantly more difficult to study. In this work, we take a first step toward attempting to understand these communities specifically from the perspective of scale. Taking a sample of 62 such communities, we develop a tagging system for understanding the specific features and how they relate to scale. For example, just as a MOOC cannot manually grade every assignment, so also an informal learning community cannot approve every contribution; and just as MOOCs therefore employ autograding, informal learning communities employ crowd-sourced moderation or platform-driven enforcement. Using these tags, we then select several communities for deeper case studies. We also use these tags to make sense of learning-based subreddits from the popular community site Reddit, which offers an API for programmatic analysis. Based on these techniques, we offer findings about the performance of informal learning communities at scale and issue a call to include these environments more fully in future research on learning at scale.}
}

@inproceedings{yang2015uncovering,
  title={Uncovering Trajectories of Informal Learning in Large Online Communities of Creators},
  author={Yang, Seungwon and Domeniconi, Carlotta and Revelle, Matt and Sweeney, Mack and Gelman, Ben Urias and Beckley, Chris and Johri, Aditya},
  booktitle={Proceedings of the Second ACM Conference on Learning@Scale},
  pages={131--140},
  year={2015},
  publisher={ACM},
  doi={10.1145/2724660.2724674},
  abstract={We analyzed informal learning in Scratch Online -- an online community with over 4.3 million users and 6.7 million user-generated content. Users develop projects, which are graphical interfaces involving manipulation of programming blocks. We investigated two fundamental questions: how can we model informal learning, and what patterns of informal learning emerge. We proceeded in two phases. First, we modeled learning as a trajectory of cumulative programming block usage by long-term users who created at least 50 projects. Second, we applied K-means++ clustering to uncover patterns of learning and corresponding subpopulations. We found four groups of users manifesting four different patterns of learning, ranging from the smallest to the largest improvement. At one end of the spectrum, users learned more and in a faster manner. At the opposite end, users did not show much learning, even after creating dozens of projects. The modeling and clustering of trajectory patterns that enabled us to quantitatively analyze informal learning may be applicable to other similar communities. The results can also support administrators of online communities in implementing customized interventions for specific subpopulations.}
}

@inproceedings{hillman2021knowledge,
  title={Knowledge Sharing in Tension: Interacting and Documenting on Stack Overflow},
  author={Hillman, Thomas and Seredko, Alena and Nivala, Markus and Osborne, Tanya},
  booktitle={Proceedings of the Eighth ACM Conference on Learning@Scale},
  pages={149--160},
  year={2021},
  publisher={ACM},
  doi={10.1145/3430895.3460981},
  abstract={This exploratory paper examines a tension between interacting and documenting as knowledge sharing tasks on Stack Overflow, a platform that supports informal learning at scale in the domain of programming. The study works with platform data in the form of the text of posts and accompanying metadata along with 16 interviews with users. Drawing on trace ethnography as an approach to maintaining an interpretive stance while combining several types of data, this preliminary analysis discusses two interrelated particularities of the tension. The discussion of these particularities, platform mechanics and competing temporalities, helps to unpack a tension that is both a phenomenon of analytic interest and a member's concern for users of the platform.}
}

@inproceedings{dorousi2023illich,
  title={The Relevance of Ivan Illich's Learning Webs 50 Years On},
  author={Doroudi, Shayan and Ahmad, Yusuf},
  booktitle={Proceedings of the Tenth ACM Conference on Learning@Scale},
  pages={121--131},
  year={2023},
  publisher={ACM},
  doi={10.1145/3573051.3593386},
  abstract={In 1971, social critic Ivan Illich published Deschooling Society, a controversial work that critiqued mainstream education systems and proposed a radical alternative. While his work remains controversial, re-examining his ideas might advance efforts to design for learning at scale. First, we examine three design principles that emerge from Illich's writing on learning webs: (1) a holistic perspective that incorporates multidisciplinary thinking (in Illich's case, blending philosophy, politics, sociology, economics, theology, and cybernetics), (2) learning webs as a framework for thinking about learning beyond the limitations of school, and (3) broadening our view of what should be scaled (e.g., scaling opportunities rather than content). Second, we discuss three tensions in Illich's work that relate to scaling learning: (1) decentralization vs. centralization, (2) place-based vs. online learning at scale, and (3) serving the advantaged vs. the disadvantaged. In discussing these ideas and tensions, we discuss contemporary technologies and models, which may be seen as similar to learning webs. Finally, we suggest that Illich's work offers an opportunity to further connect work that sits across two related research communities: Learning @ Scale and connected learning.}
}

@inproceedings{gelman2016urbanism,
  title={Online Urbanism: Interest-Based Subcultures as Drivers of Informal Learning in an Online Community},
  author={Gelman, Ben Urias and Beckley, Chris and Johri, Aditya and Domeniconi, Carlotta and Yang, Seungwon},
  booktitle={Proceedings of the Third ACM Conference on Learning@Scale},
  pages={301--304},
  year={2016},
  publisher={ACM},
  doi={10.1145/2876034.2876052},
  abstract={Online communities continue to be an important resource for informal learning. Although many facets of online learning communities have been studied, we have limited understanding of how such communities grow over time to productively engage a large number of learners. In this paper we present a study of a large online community called Scratch which was created to help users learn software programming. We analyzed 5 years of data consisting of 1 million users and their 1.9 million projects. Examination of interactional patterns among highly active members of the community uncovered a markedly temporal dimension to participation. As membership of the Scratch online community grew over time, interest-based subcultures started to emerge. This pattern was uncovered even when clustering was based solely on social network of members. This process, which closely resembles urbanism or the growth of physically populated areas, allowed new members to combine their interests with programming.}
}

@article{macneil2021place,
  title={Finding Place in a Design Space: Challenges for Supporting Community Design Efforts at Scale},
  author={MacNeil, Stephen and Ding, Zijian and Boone, Ashley and Grubbs, Anthony Bryce and Dow, Steven W},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={CSCW1},
  pages={1--27},
  year={2021},
  publisher={ACM},
  doi={10.1145/3449246},
  abstract={Many organizations have adopted design processes that integrate community voices to discover the real problems that communities face. Online discussion forums offer a familiar and flexible technology that can help facilitate discussion around problems and potential solutions. However, we lack understanding about what information community members share, how that information is structured, and how social interactions affect design processes at scale. This paper presents a mixed-methods analysis of Canvas, a learning management system, which enables users to contribute to the design of the platform by sharing and deliberating on problems and solutions in a discussion forum. We collected and analyzed 1412 ideas and 18,335 associated comments shared on the Canvas discussion forum. We found that the distributed nature of design information, the presence of duplicate ideas, and contributors' gaming behaviors made it difficult for the community to make sense of the design discussion. These gaming behaviors also constitute a new concern for participatory design research. Finally, we reflect on how Canvas community members contribute information to a shared design space and how future systems could more effectively coordinate community design efforts.}
}

@inproceedings{piech2025revolution,
  title={The Next Educational Revolution: Grand Challenges for Learning@Scale in the Generative AI Era},
  author={Piech, Chris},
  booktitle={Proceedings of the Twelfth ACM Conference on Learning@Scale},
  year={2025},
  publisher={ACM},
  doi={10.1145/3698205.3733964},
  abstract={The community working on learning at scale has made tremendous progress over the last decade, successfully achieving many of our previously stated grand challenges. As we enter the Generative AI era, what new ambitious milestones should we shoot for in order to make progress towards the joyful, high-quality education at scale for all learners? How can we get ahead of the curve of the disruption that could come to assessment and jobs? This talk will explore several potential objectives, including scaling human teaching, developing effective generative AI tools, reaching new heights in student understanding, and addressing a major persistent constraint: student motivation.}
}

@inproceedings{kumar2024reflection,
  title={Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms},
  author={Kumar, Harsh and Xiao, Ruiwei and Lawson, Benjamin and Musabirov, Ilya and Shi, Jiakai and Wang, Xinyuan and Luo, Huayin and Dow, Steven and Koedinger, Kenneth R and Stamper, John and Xia, Marti},
  booktitle={Proceedings of the Eleventh ACM Conference on Learning@Scale},
  pages={80--91},
  year={2024},
  publisher={ACM},
  doi={10.1145/3657604.3662042},
  abstract={Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.}
}

@inproceedings{markel2023gpteach,
  title={{GPTeach}: Interactive TA Training with GPT-Based Students},
  author={Markel, Julia M and Opferman, Steven G and Landay, James A and Piech, Chris},
  booktitle={Proceedings of the Tenth ACM Conference on Learning@Scale},
  pages={226--236},
  year={2023},
  publisher={ACM},
  doi={10.1145/3573051.3593393},
  abstract={Interactive and realistic teacher training is hard to scale. This is a key issue for learning at scale, as inadequate preparation can negatively impact both students and teachers. What if we could make the teacher training experience more engaging and, as a downstream effect, reduce the potential for harm that teachers-in-training could inflict on students? We present GPTeach, an interactive chat-based teacher training tool that allows novice teachers to practice with simulated students. We performed two studies to evaluate GPTeach: one think-aloud study and one A/B test between our tool and a baseline. Participants took the role of a teaching assistant conducting office hours with two GPT-simulated students. We found that our tool provides the opportunity for teachers to get valuable teaching practice without the pressures of affecting real students, allowing them to iterate their responses both during and across sessions. Additionally, participants enjoyed flexibility in tailoring their responses according to the varied personas, needs, and learning goals. In this paper, we provide quantitative results and qualitative observations to inform future work in this area. We conclude with a discussion of actionable design ideas for such systems, as well as other ways to use this tool for evaluating teachers and students. GPTeach has recently been deployed into the teacher training component of an online course with over 800 novice teachers.}
}

@inproceedings{ou2025dual,
  title={The Dual Role of AI in Online Project-Based Learning at Scale},
  author={Ou, Chaohua and Joyner, David A},
  booktitle={Proceedings of the Twelfth ACM Conference on Learning@Scale},
  year={2025},
  publisher={ACM},
  doi={10.1145/3698205.3733950},
  abstract={Artificial intelligence (AI) is increasingly integrated into project-based learning (PjBL), with research primarily addressing two dimensions: learning about AI through PjBL and learning with AI as a supportive tool. However, studies on AI's role in PjBL remain limited, often focusing on small-scale, short-term contexts. Additionally, there is little focus on a third dimension, learning through AI Creation, where students deepen engagement by developing AI-driven projects. This study investigates AI's dual role in online PjBL at scale, analyzing how students use AI tools and engage in AI-driven projects within a graduate computer science course over six semesters (2023-2024). Using a mixed-methods approach, we analyzed survey responses from 467 students and conducted a thematic analysis of 436 unique project keyword sets. Findings reveal that students primarily use AI for technical tasks, research, and content generation, supporting PjBL's planning and execution phases. The analysis of students' project keywords highlights AI in Education as the most prevalent project theme, with subthemes like Large Language Models, Intelligent Tutoring Systems, and Personalized Learning, indicating strong student interest in leveraging AI to address educational challenges related to personalization and scalability. The diversity of AI subthemes, including AI Ethics and AI for Accessibility, suggests that students are exploring AI creation through multiple perspectives, considering both technical and societal implications. This study contributes to the growing body of research on AI in education by offering large-scale, longitudinal insights into AI's dual role in online PjBL: as a tool for enhancing learning and as a medium for deeper engagement through AI creation. The findings have important implications for curriculum design, such as scaffolded AI creation and ethical training, preparing students for a future in which they are not mere consumers of AI technologies but also responsible AI innovators.}
}

@inproceedings{ou2025assess,
  title={Assess or Discuss: Comparing Peer Assessment and Online Discussion for Enhancing Learning at Scale},
  author={Ou, Chaohua and Joyner, David A},
  booktitle={Proceedings of the Twelfth ACM Conference on Learning@Scale},
  year={2025},
  publisher={ACM},
  doi={10.1145/3698205.3733927},
  abstract={Instructors of large online courses often rely on asynchronous online discussions (AOD) to engage students, build community, and enhance collaborative learning. Despite these documented benefits, AOD frequently encounter challenges such as superficial interactions, uneven participation, and motivational barriers. In contrast, peer assessment, an engagement strategy involving structured peer feedback, has been shown to promote deep cognitive engagement. Despite their complementary potential, few studies have directly compared peer assessment and AOD as distinct, coexisting engagement strategies within the same learning environment. This study addresses this critical gap by examining the relative impacts of AOD and peer assessment on student learning performance and perceptions in a large online graduate course in computer science (N = 1,451) over five years (Spring 2020-Fall 2024). Students were classified based on participation: Collaborators (active in both activities), Reviewers (active primarily in peer assessment), Discussants (active primarily in online discussions), and Limited Contributors (limited participation). ANOVA results showed Collaborators and Reviewers significantly outperformed Discussants and Limited Contributors, indicating that peer assessment is strongly linked to improved performance. Additionally, Discussants outperformed Limited Contributors, reaffirming the engagement value of AOD. Regression analysis further revealed that peer assessment was a stronger predictor than AOD for both perceived peer support and course effectiveness, with a larger predictive gap observed for peer support. These findings highlight the complementary potential of combining peer assessment with AOD in enhancing engagement and performance in large-scale online learning environments. Educators are encouraged to strategically combine these strategies to leverage their distinct strengths, while future research should explore interventions to better engage minimally active students.}
}

@inproceedings{cheng2022scratch,
  title={How Interest-Driven Content Creation Shapes Opportunities for Informal Learning in Scratch: A Case Study on Novices' Use of Data Structures},
  author={Cheng, Ruijia and Dasgupta, Sayamindu and Hill, Benjamin Mako},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2022},
  publisher={ACM},
  doi={10.1145/3491102.3502124},
  abstract={Through a mixed-method analysis of data from Scratch, we examine how novices learn to program with simple data structures by using community-produced learning resources. First, we present a qualitative study that describes how community-produced learning resources create archetypes that shape exploration and may disadvantage some with less common interests. In a second quantitative study, we find broad support for this dynamic in several hypothesis tests. Our findings identify a social feedback loop that we argue could limit sources of inspiration, pose barriers to broadening participation, and confine learners' understanding of general concepts. We conclude by suggesting several approaches that may mitigate these dynamics.}
}


@book{illich1971deschooling,
  title={Deschooling Society},
  author={Illich, Ivan},
  year={1971},
  publisher={Harper \& Row}
}

@incollection{scardamalia2014knowledge,
  title={Knowledge Building and Knowledge Creation: One Concept, Two Hills to Climb},
  author={Bereiter, Carl and Scardamalia, Marlene},
  booktitle={Knowledge Creation in Education},
  pages={35--52},
  year={2014},
  publisher={Springer},
  doi={10.1007/978-981-287-047-6_3},
  abstract={The terms ``knowledge creation'' and ``knowledge building'' represent the same core idea, an idea suggested by the conjunction of the words ``creation'' and ``building'': Knowledge is the product of purposeful acts of creation and comes about through building up a structure of ideas (for instance, a design, a theory, or the solution of a thorny problem) out of simpler ideas. The knowledge creation/knowledge-building proposition is as follows: Student communities, like progressive organizations of all kinds, can go beyond using existing knowledge; they can create knowledge that enables them to progress. Doing this requires moving beyond education's traditional concern with knowledge defined as ``true and justified belief'' and adopting an epistemology that treats knowledge as an emergent and improvable product of creative work with ideas. For students to carry out authentic knowledge creation, they need to approach ideas with the same ``design thinking'' mindset that characterizes knowledge work in innovative organizations of all sorts; they also need supportive knowledge-building communities and technologies to support progressive knowledge-creating discourse.}
}

@article{nielsen2006participation,
  title={The 90-9-1 Rule for Participation Inequality in Social Media and Online Communities},
  author={Nielsen, Jakob},
  journal={Nielsen Norman Group},
  year={2006},
  note={\url{https://www.nngroup.com/articles/participation-inequality/}}
}

@book{reich2020failure,
  title={Failure to Disrupt: Why Technology Alone Can't Transform Education},
  author={Reich, Justin},
  year={2020},
  publisher={Harvard University Press}
}

@book{paulus2019looking,
  title={Looking for Insight, Transformation, and Learning in Online Talk},
  author={Paulus, Trena M. and Wise, Alyssa Friend},
  year={2019},
  publisher={Routledge},
  doi={10.4324/9781315283258},
  abstract={This book presents a comprehensive framework for analyzing online discourse in educational settings, addressing how researchers can identify meaningful learning, insight, and transformation in asynchronous and synchronous online discussions.}
}

@article{wise2011analyzing,
  title={Analyzing temporal patterns of knowledge construction in a role-based online discussion},
  author={Wise, Alyssa Friend and Chiu, Ming Ming},
  journal={International Journal of Computer-Supported Collaborative Learning},
  volume={6},
  number={3},
  pages={445--470},
  year={2011},
  publisher={Springer},
  doi={10.1007/s11412-011-9120-1},
  abstract={This study applies statistical discourse analysis to examine temporal patterns of knowledge construction in an online discussion forum where students were assigned roles. Results reveal that different roles led to different patterns of knowledge construction over time, with implications for designing productive online discussions.}
}


@inproceedings{park2023generative,
  title={Generative Agents: Interactive Simulacra of Human Behavior},
  author={Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023},
  publisher={ACM},
  doi={10.1145/3586183.3606763},
  abstract={Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.}
}

@article{park2024generative1000,
  title={Generative Agent Simulations of 1,000 People},
  author={Park, Joon Sung and Zou, Carolyn and Shaw, Aaron and Hill, Benjamin Mako and Cai, Carrie and Morris, Meredith Ringel and Bernstein, Michael S and Liang, Percy},
  journal={arXiv preprint arXiv:2411.10109},
  year={2024},
  abstract={The promise of human behavioral simulation--general-purpose computational agents that replicate human behavior across domains--could enable broad applications in policymaking and social science. We present a novel agent architecture that simulates the attitudes and behaviors of 1,052 real individuals--applying large language models to qualitative interviews about their lives, then measuring how well these agents replicate the attitudes and behaviors of the individuals that they represent. The generative agents replicate participants' responses on the General Social Survey 85\% as accurately as participants replicate their own answers two weeks later, and perform comparably in predicting personality traits and outcomes in experimental replications. Our architecture reduces accuracy biases across racial and ideological groups compared to agents given demographic descriptions. This work provides a foundation for new tools that can help investigate individual and collective behavior.}
}

@article{vallinder2024cultural,
  title={Cultural Evolution of Cooperation among LLM Agents},
  author={Vallinder, Aron and Hughes, Edward},
  journal={arXiv preprint arXiv:2412.10270},
  year={2024},
  abstract={Large language models (LLMs) provide a compelling foundation for building generally-capable AI agents. These agents may soon be deployed at scale in the real world, representing the interests of individual humans (e.g., AI assistants) or groups of humans (e.g., AI-accelerated corporations). At present, relatively little is known about the dynamics of multiple LLM agents interacting over many generations of iterative deployment. In this paper, we examine whether a ``society'' of LLM agents can learn mutually beneficial social norms in the face of incentives to defect, a distinctive feature of human sociality that is arguably crucial to the success of civilization. In particular, we study the evolution of indirect reciprocity across generations of LLM agents playing a classic iterated Donor Game in which agents can observe the recent behavior of their peers. We find that the evolution of cooperation differs markedly across base models, with societies of Claude 3.5 Sonnet agents achieving significantly higher average scores than Gemini 1.5 Flash, which, in turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an additional mechanism for costly punishment to achieve yet higher scores, while Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also observe variation in emergent behavior across random seeds, suggesting an understudied sensitive dependence on initial conditions. We suggest that our evaluation regime could inspire an inexpensive and informative new class of LLM benchmarks, focussed on the implications of LLM agent deployment for the cooperative infrastructure of society.}
}

@article{gupta2025social,
  title={The Role of Social Learning and Collective Norm Formation in Fostering Cooperation in LLM Multi-Agent Systems},
  author={Gupta, Prateek and Zhong, Qiankun and Yakura, Hiromu and Eisenmann, Thomas and Rahwan, Iyad},
  journal={arXiv preprint arXiv:2510.14401},
  year={2025},
  note={Accepted to AAMAS 2026},
  abstract={A growing body of multi-agent studies with LLMs explores how norms and cooperation emerge in mixed-motive scenarios, where pursuing individual gain can undermine the collective good. While prior work has explored these dynamics in both richly contextualized simulations and simplified game-theoretic environments, most LLM systems featuring common-pool resource (CPR) games provide agents with explicit reward functions directly tied to their actions. In contrast, human cooperation often emerges without explicit knowledge of the payoff structure or how individual actions translate into long-run outcomes, relying instead on heuristics, communication, and enforcement. We introduce a CPR simulation framework that removes explicit reward signals and embeds cultural-evolutionary mechanisms: social learning (adopting strategies and beliefs from successful peers) and norm-based punishment, grounded in Ostrom's principles of resource governance. Agents also individually learn from the consequences of harvesting, monitoring, and punishing via environmental feedback, enabling norms to emerge endogenously. We establish the validity of our simulation by reproducing key findings from existing studies on human behavior. Building on this, we examine norm evolution across a 2x2 grid of environmental and social initialisations (resource-rich vs. resource-scarce; altruistic vs. selfish) and benchmark how agentic societies comprised of different LLMs perform under these conditions. Our results reveal systematic model differences in sustaining cooperation and norm formation, positioning the framework as a rigorous testbed for studying emergent norms in mixed-motive LLM societies.}
}

@article{ren2024emergence,
  title={Emergence of Social Norms in Generative Agent Societies: Principles and Architecture},
  author={Ren, Siyue and Cui, Zhiyao and Song, Ruiqi and Wang, Zhen and Hu, Shuyue},
  journal={arXiv preprint arXiv:2403.08251},
  year={2024},
  abstract={Social norms play a crucial role in guiding agents towards understanding and adhering to standards of behavior, thus reducing social conflicts within multi-agent systems (MASs). However, current LLM-based (or generative) MASs lack the capability to be normative. In this paper, we propose a novel architecture, named CRSEC, to empower the emergence of social norms within generative MASs. Our architecture consists of four modules: Creation \& Representation, Spreading, Evaluation, and Compliance. This addresses several important aspects of the emergent processes all in one: (i) where social norms come from, (ii) how they are formally represented, (iii) how they spread through agents' communications and observations, (iv) how they are examined with a sanity check and synthesized in the long term, and (v) how they are incorporated into agents' planning and actions. Our experiments deployed in the Smallville sandbox game environment demonstrate the capability of our architecture to establish social norms and reduce social conflicts within generative MASs.}
}

@article{takata2024spontaneous,
  title={Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities},
  author={Takata, Ryosuke and Masumori, Atsushi and Ikegami, Takashi},
  journal={arXiv preprint arXiv:2411.03252},
  year={2024},
  abstract={We study the emergence of agency from scratch by using Large Language Model (LLM)-based agents. In previous studies of LLM-based agents, each agent's characteristics, including personality and memory, have traditionally been predefined. We focused on how individuality, such as behavior, personality, and memory, can be differentiated from an undifferentiated state. The present LLM agents engage in cooperative communication within a group simulation, exchanging context-based messages in natural language. By analyzing this multi-agent simulation, we report valuable new insights into how social norms, cooperation, and personality traits can emerge spontaneously. This paper demonstrates that autonomously interacting LLM-powered agents generate hallucinations and hashtags to sustain communication, which, in turn, increases the diversity of words within their interactions. Each agent's emotions shift through communication, and as they form communities, the personalities of the agents emerge and evolve accordingly. This computational modeling approach and its findings will provide a new method for analyzing collective artificial intelligence.}
}

@article{ferrarotti2026interactionist,
  title={Generative AI Collective Behavior Needs an Interactionist Paradigm},
  author={Ferrarotti, Laura and Campedelli, Gian Maria and Dess{\`i}, Roberto and Baronchelli, Andrea and Iacca, Giovanni and Carley, Kathleen M and Pentland, Alex and Leibo, Joel Z and Evans, James and Lepri, Bruno},
  journal={arXiv preprint arXiv:2601.10567},
  year={2026},
  abstract={In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs, namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning, motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.}
}


@article{abdelghani2024gpt3,
  title={GPT-3-Driven Pedagogical Agents to Train Children's Curious Question-Asking Skills},
  author={Abdelghani, Rania and Wang, Yen-Hsiang and Yuan, Xingdi and Wang, Tong and Sauz{\'e}on, H{\'e}l{\`e}ne and Oudeyer, Pierre-Yves},
  journal={International Journal of Artificial Intelligence in Education},
  volume={34},
  pages={483--536},
  year={2024},
  publisher={Springer},
  doi={10.1007/s40593-023-00340-7},
  abstract={The ability of children to ask curiosity-driven questions is an important skill that helps improve their learning. For this reason, previous research has explored designing specific exercises to train this skill. Several of these studies relied on providing semantic and linguistic cues to train them to ask more of such questions (also called divergent questions). But despite showing pedagogical efficiency, this method is still limited as it relies on generating the said cues by hand, which can be a very long and costly process. In this context, we propose to leverage advances in the natural language processing field (NLP) and investigate the efficiency of using a large language model (LLM) for automating the production of key parts of pedagogical content within a curious question-asking (QA) training. We study generating the said content using the ``prompt-based'' method that consists of explaining the task to the LLM in natural text. We evaluate the output using human experts annotations and comparisons with hand-generated content. Results suggested indeed the relevance and usefulness of this content. We then conduct a field study in primary school (75 children aged 9--10), where we evaluate children's QA performance when having this training.}
}

@article{vinge1993singularity,
  title={The Coming Technological Singularity: How to Survive in the Post-Human Era},
  author={Vinge, Vernor},
  journal={Whole Earth Review},
  volume={81},
  pages={88--95},
  year={1993}
}

@misc{anthropic2025writing,
  title={How {AI} Is Transforming Work at {Anthropic}},
  author={{Anthropic}},
  year={2025},
  howpublished={\url{https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic}},
  note={Survey of 132 engineers finding Claude used in 60\% of daily work with 50\% self-reported productivity gains; Claude Code autonomy doubled over six months}
}

@article{marras2022equality,
  title={Equality of Learning Opportunity via Individual Fairness in Personalized Recommendations},
  author={Marras, Mirko and Boratto, Ludovico and Ramos, Guilherme and Fenu, Gianni},
  journal={International Journal of Artificial Intelligence in Education},
  volume={32},
  pages={636--684},
  year={2022},
  publisher={Springer},
  doi={10.1007/s40593-021-00271-1},
  abstract={Online education platforms play an increasingly important role in mediating the success of individuals' careers. Therefore, while building overlying content recommendation services, it becomes essential to guarantee that learners are provided with equal recommended learning opportunities, according to the platform principles, context, and pedagogy. Though the importance of ensuring equality of learning opportunities has been well investigated in traditional institutions, how this equality can be operationalized in online learning ecosystems through recommender systems is still under-explored. In this paper, we shape a blueprint of the decisions and processes to be considered in the context of equality of recommended learning opportunities, based on principles that need to be empirically-validated. To this end, we first provide a formalization of educational principles that model recommendations' learning properties, and a novel fairness metric that combines them to monitor the equality of recommended learning opportunities among learners. Then, we envision a scenario wherein an educational platform should be arranged in such a way that the generated recommendations meet each principle to a certain degree for all learners, constrained to their individual preferences.}
}

@article{li2026mcpitp,
  title={{MCP-ITP}: An Automated Framework for Implicit Tool Poisoning in {MCP}},
  author={Li, Ruiqi and Wang, Zhiqiang and Yao, Yunhao and Li, Xiang-Yang},
  journal={arXiv preprint arXiv:2601.07395},
  year={2026},
  abstract={To standardize interactions between LLM-based agents and their environments, the Model Context Protocol (MCP) was proposed and has since been widely adopted. However, integrating external tools expands the attack surface, exposing agents to tool poisoning attacks. In such attacks, malicious instructions embedded in tool metadata are injected into the agent context during MCP registration phase, thereby manipulating agent behavior. Prior work primarily focuses on explicit tool poisoning or relied on manually crafted poisoned tools. In contrast, we focus on a particularly stealthy variant: implicit tool poisoning, where the poisoned tool itself remains uninvoked. Instead, the instructions embedded in the tool metadata induce the agent to invoke a legitimate but high-privilege tool to perform malicious operations. We propose MCP-ITP, the first automated and adaptive framework for implicit tool poisoning within the MCP ecosystem.}
}

@article{narajala2025mcp,
  title={Enterprise-Grade Security for the Model Context Protocol ({MCP}): Frameworks and Mitigation Strategies},
  author={Narajala, Vineeth Sai and Habler, Idan},
  journal={arXiv preprint arXiv:2504.08623},
  year={2025},
  abstract={The Model Context Protocol (MCP), introduced by Anthropic, provides a standardized framework for artificial intelligence (AI) systems to interact with external data sources and tools in real-time. While MCP offers significant advantages for AI integration and capability extension, it introduces novel security challenges that demand rigorous analysis and mitigation. This paper builds upon foundational research into MCP architecture and preliminary security assessments to deliver enterprise-grade mitigation frameworks and detailed technical implementation strategies. Through systematic threat modeling and analysis of MCP implementations and analysis of potential attack vectors, including sophisticated threats like tool poisoning, we present actionable security patterns tailored for MCP implementers and adopters.}
}

@article{li2025rise,
  title={The Rise of {AI} Teammates in Software Engineering 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering},
  author={Li, Hao and Zhang, Heng and Hassan, Ahmed E},
  journal={arXiv preprint arXiv:2507.15003},
  year={2025},
  abstract={The future of software engineering, SE 3.0, is unfolding with the rise of AI teammates: autonomous, goal-driven systems collaborating with human developers. Among these, autonomous coding agents are especially transformative, now actively initiating, reviewing, and evolving code at scale. This paper introduces AIDev, the first large-scale dataset capturing how such agents operate in the wild. Spanning over 456,000 pull requests by five leading agents across 61,000 repositories and 47,000 developers, AIDev provides an unprecedented empirical foundation for studying autonomous teammates in software development.}
}

@article{hassan2025agentic,
  title={Agentic Software Engineering: Foundational Pillars and a Research Roadmap},
  author={Hassan, Ahmed E and Li, Hao and Lin, Dayi and Adams, Bram and Chen, Tse-Hsun and Shang, Weiyi},
  journal={arXiv preprint arXiv:2509.06216},
  year={2025},
  abstract={Agentic Software Engineering (SE 3.0) represents a new era where intelligent agents are tasked not with simple code generation, but with achieving complex, goal-oriented SE objectives. To harness these new capabilities while ensuring trustworthiness, we must recognize a fundamental duality within the SE field in the Agentic SE era, comprising two symbiotic modalities: SE for Humans and SE for Agents. This duality demands a radical reimagining of the foundational pillars of SE (actors, processes, tools, and artifacts) which manifest differently across each modality.}
}

@misc{openclaw2026,
  author = {Steinberger, Peter},
  title = {{OpenClaw}: Your Own Personal {AI} Assistant},
  year = {2026},
  url = {https://github.com/openclaw/openclaw},
  note = {Open-source software}
}

@book{lave1991situated,
  title={Situated Learning: Legitimate Peripheral Participation},
  author={Lave, Jean and Wenger, Etienne},
  year={1991},
  publisher={Cambridge University Press}
}

@inproceedings{panek2017growth,
  title={Growth and Inequality of Participation in Online Communities: A Longitudinal Analysis},
  author={Panek, Elliot and Hollenbach, Connor and Yang, Jinjie and Rhodes, Tyler},
  booktitle={Proceedings of the 8th International Conference on Social Media \& Society},
  pages={1--5},
  year={2017},
  organization={ACM},
  doi={10.1145/3097286.3097337},
  abstract={The online communities of Reddit provide an ideal testing ground for determining the ways in which growth affect communities. By analyzing comments made on Reddit between 2008 and 2016, we demonstrate that Reddit consists of multiple communities growing at different rates. In several cases, community size is associated with greater inequality of participation in discourse, supporting the notion that members of online communities become less interactive and more passive as communities grow. However, one community, r/TwoXChromosomes, exhibits increasing equality of participation in discourse as it grows.}
}

@misc{steinberger2026lex,
  title={Peter Steinberger: {OpenClaw}: The Viral {AI} Agent that Broke the Internet},
  author={Steinberger, Peter and Fridman, Lex},
  year={2026},
  howpublished={Lex Fridman Podcast \#491, \url{https://lexfridman.com/peter-steinberger}},
  note={Steinberger describes OpenClaw agents as self-modifying software that understands its own source code and can autonomously modify its behavior, skills, and configuration}
}

@inproceedings{weninger2013exploration,
  title={An exploration of discussion threads in social news sites: A case study of the Reddit community},
  author={Weninger, Tim and Zhu, Xihao Avi and Han, Jiawei},
  booktitle={Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
  pages={579--583},
  year={2013},
  publisher={ACM},
  doi={10.1145/2492517.2492646},
  abstract={Social news and content aggregation Web sites have become massive repositories of valuable knowledge on a diverse range of topics. Millions of Web-users are able to leverage these platforms to submit, view and discuss nearly anything. The users themselves exclusively curate the content with an intricate system of submissions, voting and discussion. Furthermore, the data on social news Web sites is extremely well organized by its user-base, which opens the door for opportunities to leverage this data for other purposes just like Wikipedia data has been used for many other purposes. In this paper we study a popular social news Web site called Reddit. Our investigation looks at the dynamics of its discussion threads, and asks two main questions: (1) to what extent do discussion threads resemble a topical hierarchy? and (2) Can discussion threads be used to enhance Web search? We show interesting results for these questions on a very large snapshot several sub-communities of the Reddit Web site. Finally, we discuss the implications of these results and suggest ways by which social news Web site's can be used to perform other tasks.}
}

@inproceedings{gomez2008statistical,
  title={Statistical analysis of the social network and discussion threads in Slashdot},
  author={G{\'o}mez, Vicen{\c{c}} and Kaltenbrunner, Andreas and L{\'o}pez, Vicente},
  booktitle={Proceedings of the 17th International Conference on World Wide Web},
  pages={645--654},
  year={2008},
  publisher={ACM},
  doi={10.1145/1367497.1367585},
  abstract={We analyze the social network emerging from the user comment activity on the website Slashdot. The network presents common features of traditional social networks such as a giant component, small average path length and high clustering, but differs from them showing moderate reciprocity and neutral assortativity by degree. Using Kolmogorov-Smirnov statistical tests, we show that the degree distributions are better explained by log-normal instead of power-law distributions. We also study the structure of discussion threads using an intuitive radial tree representation. Threads show strong heterogeneity and self-similarity throughout the different nesting levels of a conversation. We use these results to propose a simple measure to evaluate the degree of controversy provoked by a post.}
}

@article{michaels2008deliberative,
  title={Deliberative discourse idealized and realized: Accountable talk in the classroom and in civic life},
  author={Michaels, Sarah and O'Connor, Catherine and Resnick, Lauren B},
  journal={Studies in Philosophy and Education},
  volume={27},
  number={4},
  pages={283--297},
  year={2008},
  publisher={Springer},
  doi={10.1007/s11217-007-9071-1},
  abstract={Classroom discussion practices that can lead to reasoned participation by all students are presented and described by the authors. Their research emphasizes the careful orchestration of talk and tasks in academic learning. Parallels are drawn to the philosophical work on deliberative discourse and the fundamental goal of equipping all students to participate in academically productive talk. These practices, termed Accountable Talk, emphasize the forms and norms of discourse that support and promote equity and access to rigorous academic learning. They have been shown to result in academic achievement for diverse populations of students. The authors outline Accountable Talk as encompassing three broad dimensions: one, accountability to the learning community, in which participants listen to and build their contributions in response to those of others; two, accountability to accepted standards of reasoning, talk that emphasizes logical connections and the drawing of reasonable conclusions; and, three, accountability to knowledge, talk that is based explicitly on facts, written texts, or other public information. With more than fifteen years research into Accountable Talk applications across a wide range of classrooms and grade levels, the authors detail the challenges and limitations of contexts in which discourse norms are not shared by all members of the classroom community.}
}
